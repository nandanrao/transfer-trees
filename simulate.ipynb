{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install densratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# 1.\n",
    "# Make non-linear in such a way that you cannot extrapolate to unseen P(Y,X)\n",
    "\n",
    "# 2. \n",
    "# Use importance estimation to extrapolate.\n",
    "\n",
    "# 3. \n",
    "# Show that when H|Z vs Z|H, extrapolation fails even with importance estimation. \n",
    "\n",
    "# 4\n",
    "# Make true model such that excluding variables should recover a model that is \"robust\" (P(X|H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_dat(vars_):\n",
    "    f, axes = plt.subplots(len(vars_), 1, sharex=True, figsize=(20, 10))\n",
    "\n",
    "    for (H,title),ax in zip(vars_, axes):\n",
    "        for i,h in zip(['A', 'B', 'C', 'D'], H):\n",
    "            sns.distplot(h, label = i, ax=ax)\n",
    "        ax.legend()\n",
    "        ax.set_title(title)\n",
    "        \n",
    "    # plt.title(title)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "# Y := f(H, W, X, Z, N_Y)\n",
    "# Y := f(W, X, Z, N_Y)\n",
    "def fn(h, v, z, w):\n",
    "    val = -1*(h > np.mean(h))*w*h**2 + w*h + w*z + np.random.normal(0, 5, size = h.shape[0])\n",
    "    return val/10\n",
    "\n",
    "\n",
    "def generate_data(N, fn, hidden_cause = True, plot=False, hiddens = [(20,2)]*4, v_conds = [(250,5,5)]*4):\n",
    "    # H is latent variable, distribution changes (not )\n",
    "    H = [gamma.rvs(a, loc=b, scale=1, size=N) for a,b in hiddens]\n",
    "\n",
    "    # V := f(H, N_X)\n",
    "    V = [(1/(h))*c + np.random.gamma(a, b, size=N) for h,(c,a,b) in zip(H, v_conds)]\n",
    "\n",
    "\n",
    "    if not hidden_cause:\n",
    "        V,H = deepcopy(H), deepcopy(V)\n",
    "\n",
    "    # Z = [gamma.rvs(int(np.random.normal(40, 10)), loc=0, scale=1, size=N) for h in H]\n",
    "    # Z := f(N_Z) \n",
    "    Z = [gamma.rvs(2, loc=1, scale=3, size=N) for h in H]\n",
    "\n",
    "    # W := f(N_W) -- TREATMENT\n",
    "    W = [np.random.binomial(1, 0.5, size=N) for h in H]\n",
    "\n",
    "    # Y:= fn(H, V, Z, W, N_Y)\n",
    "    Y = [fn(H[idx], V[idx], Z[idx], W[idx]) for idx in range(4)]\n",
    "\n",
    "    taus = [fn(h,v,z,1) - fn(h,v,z,0) for h,v,z in zip(H,V,Z)]\n",
    "    \n",
    "    if plot:\n",
    "        plot_dat([(H,'H'), (V, 'V') , (Z, 'Z'), (Y, 'Y'), (taus, 'tau')])\n",
    "\n",
    "    return [(y, np.array([w,v,z]).T, tau) for y,v,z,w,h,tau in zip(Y, V, Z, W, H, taus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import wasserstein_distance\n",
    "from itertools import combinations\n",
    "\n",
    "def kde_score(X):\n",
    "    return gaussian_kde(X).evaluate\n",
    "\n",
    "def score_wasserstein(dat, phi, model, train_idx):\n",
    "    y_train, X_train, _ = dat[train_idx]\n",
    "    model.fit(phi(X_train), y_train)\n",
    "    resids = [model.predict(phi(x)) - y for y,x,_ in dat]\n",
    "    dists = [wasserstein_distance(resids[0], r) for r in resids]\n",
    "    mss = [np.mean(r**2) for r in resids]\n",
    "    score = np.sum(dists)\n",
    "    return score\n",
    "\n",
    "\n",
    "def filter_dat(d, idxs):\n",
    "    return [(y, x[:,idxs],tau) for y,x,tau in d]\n",
    "\n",
    "def search_wasserstein(dat, phi, model, train_idx):\n",
    "    s = dat[0][1].shape[1]\n",
    "\n",
    "    combs = [j for i in range(1,s) \n",
    "             for j in combinations(range(1, s), i)]\n",
    "\n",
    "    combs = [[0] + list(c) for c in combs]\n",
    "\n",
    "    scores = [score_wasserstein(filter_dat(dat, i), phi, model, train_idx) for i in combs]\n",
    "\n",
    "    return combs[np.argmin(scores)]\n",
    "\n",
    "\n",
    "def run_model(dat, model, phi, train_idx, target_idx, use_weights = None, model_search = False):\n",
    "    X_train, X_target = dat[train_idx][1], dat[target_idx][1]\n",
    "\n",
    "    if model_search:\n",
    "        # exclude the target in the model search\n",
    "        dd = [d for i,d in enumerate(dat) if i != target_idx]\n",
    "        idxs = search_wasserstein(dd, phi, model, train_idx)\n",
    "        # print('Choosing variables: ', idxs)\n",
    "    else:\n",
    "        idxs = range(0, X_train.shape[1])\n",
    "\n",
    "\n",
    "    if use_weights is not None:\n",
    "        ps, pt = kde_score(X_train[:, use_weights]), kde_score(X_target[:, use_weights])\n",
    "        weights = pt(X_train[:, use_weights]) / ps(X_train[:, use_weights])\n",
    "    else:\n",
    "        weights = np.ones(X_train.shape[0])\n",
    "\n",
    "\n",
    "    d = [(phi(x[:, idxs]), x[:, 0], y) for y,x,tau in dat]\n",
    "\n",
    "    model.fit(d[train_idx][0], d[train_idx][2], sample_weight=weights)\n",
    "\n",
    "    y0 = [np.mean(model.predict(p[w == 0])) for p,w,y in d]\n",
    "    y1 = [np.mean(model.predict(p[w == 1])) for p,w,y in d]\n",
    "\n",
    "    pred_ates = [a-b for a,b in zip(y1, y0)]\n",
    "    _, _, true_ates = zip(*dat)\n",
    "\n",
    "    return [np.round(np.abs(p-np.mean(t)), 4) for p,t in zip(pred_ates, true_ates)]\n",
    "\n",
    "phi = PolynomialFeatures(degree=2, include_bias=True).fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hiddens = [(25, 2), (4, 15), (4, 20), (2, 25)]\n",
    "# hiddens = [(10,2)]*4\n",
    "v_conds = [(500,2,2)]*4\n",
    "# v_conds = [(250,2,30), (250,5,10), (500,15,5), (500,40,2)]\n",
    "\n",
    "dat = generate_data(2000, \n",
    "                    fn, \n",
    "                    hidden_cause = False, \n",
    "                    plot = False, \n",
    "                    hiddens = hiddens,\n",
    "                    v_conds = v_conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from trees import build_tree, mse, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y, X, tau = dat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tree = build_tree(mse, phi(X), y, np.arange(1,10), 5, 0.0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node(dim=6, thresh=1.6751720397780472, gain=250.6995844541998, left=Node(dim=8, thresh=35.08843057675259, gain=1.0049337677610772, left=Leaf(prediction=-10.054217787279395, score=495.4986611030132, N=10), right=Node(dim=1, thresh=0.5, gain=0.04886421368746485, left=Node(dim=8, thresh=42.24091763323145, gain=0.0011156622558234908, left=Leaf(prediction=0.33937912628930905, score=0.16175088802730778, N=10), right=Node(dim=8, thresh=45.63447084189335, gain=0.0018710982962970857, left=Leaf(prediction=-0.33812641465206406, score=0.09244867000261951, N=15), right=Leaf(prediction=0.012441948298714913, score=0.2521327209107257, N=955))), right=Leaf(prediction=1.9551452355894579, score=0.07364086568450202, N=13))), right=Node(dim=2, thresh=24.22412455627345, gain=717.9626243435771, left=Node(dim=2, thresh=19.585729236286323, gain=235.25491068782162, left=Node(dim=2, thresh=16.318933304986967, gain=260.25115249661695, left=Leaf(prediction=-139.29775655879394, score=338.8996932048696, N=10), right=Node(dim=2, thresh=18.511657851050174, gain=44.532095031067, left=Leaf(prediction=-101.38101157416065, score=484.5164104583277, N=27), right=Leaf(prediction=-88.03233055273104, score=283.6676625147424, N=28))), right=Node(dim=2, thresh=22.4443423595493, gain=81.43171087140922, left=Node(dim=8, thresh=127.15092407660943, gain=10.665497354199317, left=Leaf(prediction=-75.69444644411907, score=231.36920348544157, N=64), right=Leaf(prediction=-69.16283183387165, score=110.34679982961786, N=64)), right=Node(dim=2, thresh=22.74457911936996, gain=24.395700436016114, left=Leaf(prediction=-42.06874678925209, score=1411.338756871116, N=16), right=Leaf(prediction=-56.3404858838504, score=1127.1876301492462, N=99)))), right=Node(dim=2, thresh=27.471259991193172, gain=98.15669453036196, left=Node(dim=3, thresh=2.1526048326667295, gain=36.77955498121946, left=Leaf(prediction=-55.49114958399221, score=971.5384080144486, N=11), right=Node(dim=2, thresh=26.09390369276518, gain=24.374478303410115, left=Leaf(prediction=-29.298908104389646, score=1200.912189225174, N=147), right=Leaf(prediction=-19.300040337656284, score=1039.4541675266505, N=107))), right=Node(dim=2, thresh=29.998561426717174, gain=16.220817881642688, left=Node(dim=3, thresh=3.2825107049395403, gain=28.65460791063731, left=Leaf(prediction=-23.465963984306594, score=1065.2032574311093, N=26), right=Leaf(prediction=-8.665488404942323, score=692.4881149819845, N=142)), right=Node(dim=2, thresh=39.16376225615532, gain=7.531916939697112, left=Leaf(prediction=-1.9669752177725195, score=300.99217647912167, N=238), right=Leaf(prediction=-12.701133507659163, score=787.0704276562509, N=18))))))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "yt, Xt, tt = dat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347.9654010757514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.array([predict(x, tree) for x in phi(X)])\n",
    "\n",
    "np.mean((preds - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=5, min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347.9654010757514"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(phi(X)[:, 1:], y)\n",
    "\n",
    "# np.unique(model.predict(), return_counts = True)\n",
    "\n",
    "preds = model.predict(phi(X)[:, 1:])\n",
    "\n",
    "np.mean((preds - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 0, 7, 2, 4, 6, 5, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10618, 19.78116,  0.85286,  6.71827])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, max_depth=2, min_samples_leaf=.05)\n",
    "\n",
    "np.mean(np.array([run_model(dat, model, phi, 0, 3, use_weights = None, model_search = True) for i in range(10)]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(np.array([run_model(dat, model, phi, 0, 3, use_weights = None, model_search = False) for i in range(10)]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(np.array([run_model(dat, model, phi, 0, 3, use_weights = 1, model_search = True) for i in range(10)]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(np.array([run_model(dat, model, phi, 0, 3, use_weights = 1, model_search = False) for i in range(10)]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0418, 23.8089, 15.9848, 6.2811]"
      ]
     },
     "execution_count": 1893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "run_model(dat, model, phi, 0, 1, use_weights = None, model_search = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0418, 19.8237, 0.1206, 7.0669]"
      ]
     },
     "execution_count": 1894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(dat, model, phi, 0, 3, use_weights = None, model_search = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.8894, 43.8729, 12.3517, 12.0683]"
      ]
     },
     "execution_count": 1903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(dat, model, phi, 0, 1, use_weights = 1, model_search = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.3778, 32.2376, 12.4323, 5.3211]"
      ]
     },
     "execution_count": 1904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(dat, model, phi, 0, 3, use_weights = 1, model_search = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1802,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get residuals for \"sets\" separately\n",
    "# compute distance between residuals\n",
    "# optimize squared errors + penalty for residual distance\n",
    "\n",
    "# search for \"sets\" by looking at residuals and fitting a mixture model\n",
    "# then optimize to remove that mixture...\n",
    "\n",
    "# set up an adversarial problem: the adversary tries to find a \n",
    "# mixture model in your reiduals, the classifier tries to make force the\n",
    "# adversary to fit a 1-component mixture, for example... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/opt/conda/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "simulate.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
